# **AI 에이전트 스펙 주도 개발**

- AI 에이전트에게 **명확하고 구조화된 지침**을 제공하여 개발 작업의 효율성을 극대화하는 전략
- 단순히 명령을 내리는 것이 아니라, 인간과 AI가 공유하는 '단일 진실의 원천(Source of Truth)'으로서의 스펙을 작성하고 이를 바탕으로 작업을 위임하는 방식을 의미
- 에이전트의 생산성과 신뢰성을 높임

# **스펙 주도 개발의 핵심 원칙**

## 1. 상위 수준 비전부터 시작하고 스펙을 구조화하기

- AI 에이전트에게 작업을 맡길 때, 처음부터 모든 세부 사항을 정의하기보다는 **상위 수준의 비전과 목표를 제시하고 AI가 세부 계획을 구체화하도록 유도**하는 것이 효과적
⇒ 방향성은 인간이 통제하면서 세부 확장은 AI의 강점을 활용할 수 있음
- AI 에이전트를 위한 상위 수준 스펙은 ‘어떻게’보다 ‘무엇’과 ‘왜’에 집중하며, 사용자 스토리와 수용 기준에 집중해야 함
(ex: 사용자는 할 일을 추가, 수정, 완료할 수 있어야 하며, 데이터는 영구 저장되고 앱은 반응형이며 안전해야 한다)
⇒ AI가 사용자와 결과에 기반해 상세 스펙을 작성하게 됨
- 승인된 스펙은 SPEC.md 같은 파일로 저장하고, 필요할 때마다 관련 섹션을 에이전트에게 제공하여 컨텍스트로 활용 가능
⇒ 대화 기록이 길어지거나 에이전트를 재시작할 때 발생하는 ‘망각’을 완화

## 2. 전문적인 PRD 또는 SRS처럼 스펙 구조화하기

> PRD : 제품이 무엇(What)을 해야 하는가에 초점을 맞춰, 제품의 목표, 가치, 사용자 시나리오를 정의하는 문서
SRS : 제품을 어떻게(How) 구현할 것인가에 초점을 맞춰, 기능적/비기술적 요구사항을 상세히 기술한 문서
 ⇒ AI가 의도에 맞는 올바른 코드를 생성하기 위해서는 두 관점을 모두 다루는 것이 효과적
> 
- 가장 효과적인 스펙에는 공통적으로 여섯 가지 영역이 포함되어 있었음
    1. **명령어(Commands)** : 실제 실행 명령어를 앞부분에 배치(예: `npm test`, `pytest -v`, `npm run build`)
    2. **테스트(Testing)** : 테스트 실행 방법, 사용하는 프레임워크, 테스트 파일 위치, 커버리지 기대치 등
    3. **프로젝트 구조(Project structure) :** 소스 코드, 테스트, 문서의 위치 (예: `src/`는 애플리케이션 코드, `tests/`는 단위 테스트, `docs/`는 문서)
    4. **코드 스타일(Code style) :** 명명 규칙, 포맷팅 규칙, 좋은 출력 예시
    5. **Git 워크플로우(Git workflow) :** 브랜치 명명 규칙, 커밋 메시지 형식, PR 요구사항
    6. **작업 경계(Boundaries) :** 에이전트가 절대 건드려서는 안 되는 것들 (예: 비밀 정보, vendor 디렉터리, 프로덕션 설정, 특정 폴더 등)
- 기술 스택은 구체적으로 명시하기 (ex: “리액트 프로젝트”가 아니라 “타입스크립트, Vite, Tailwind CSS를 사용하는 리액트 18”처럼 버전과 핵심 의존성 포함)
- 일관된 형식 사용 : 프롬프트를 `<배경>` , `<지침>` , `## 도구` , `## 출력 포맷` 등과 같이 명확한 섹션으로 구분하기

ex)
    
    ```
    # 프로젝트 스펙: 팀 전용 할 일 관리 앱
    
    ## 목표
    - 소규모 팀이 작업을 관리할 수 있는 웹 앱을 구축합니다.
    
    ## 기술 스택
    - React 18+, TypeScript, Vite, Tailwind CSS
    - Node.js/Express, PostgreSQL, Prisma ORM
    
    ## 커맨드
    - Build: `npm run build`
    - Test: `npm test`
    - Lint: `npm run lint --fix`
    
    ## 프로젝트 구조
    - `src/` – 애플리케이션 코드
    - `tests/` – 테스트
    - `docs/` – 문서
    
    ## 작업 경계
    - ✅ 항상: 커밋 전 테스트 실행
    - ⚠️ 먼저 문의: DB 스키마 변경
    - 🚫 절대 금지: 비밀 정보 커밋
    ```
    

## 3. 작업을 모듈화된 프롬프트와 컨텍스트로 나누기

- 하나의 거대한 프롬프트에 모든 지시사항과 컨텍스트를 담으려는 시도는 **'지시 사항의 저주'**를 유발하여 AI의 성능을 급격히 저하시킴
    - **지시 사항의 저주 (Curse of Instructions) :** LLM에 동시에 주어지는 지시사항의 수가 늘어날수록 전체 작업 성공률은 지수적으로 감소함
    
    <img width="2784" height="1536" alt="image" src="https://github.com/user-attachments/assets/8f099aec-68e9-484f-9efc-bc222afd8481" />

    
- 작업을 모듈화하고 필요한 컨텍스트만 제공하는 전략이 중요 : 요구사항 분해, 섹션별 스펙 분할, 기능 전환 시 컨텍스트 초기화 등
- **대규모 스펙을 위한 요약 :** 필요한 컨텍스트만 제공하기 위한 유용한 기법 중 하나
    - 스펙 전체에 대한 요약이 포함된 목차를 만들어, 섹션을 핵심 키워드로 압축하고 상세 내용이 있는 위치를 참조로 남겨서 컨텍스트 과부하를 피하고 에이전트가 전체 구조를 조망하게 하는 전략
    - ex) 전체 스펙에 500 단어 분량의 “보안 요구사항” 섹션이 있다면, 이를 “보안: HTTPS 사용, API 키 보호, 입력 검증 구현(전체 스펙 §4.2 참조)” 정도로 요약
    - 이 요약은 일종의 인덱스 역할을 하며 에이전트는 필요할 때 해당 부분을 요청할 수 있음
    - 이를 구현하려면, 스펙을 작성한 뒤 에이전트에게 다음과 같이 요청 : “위 스펙을 각 섹션의 핵심 포인트와 참조 태그를 포함한 매우 간결한 개요로 요약해 주세요.”
- **서브에이전트 또는 스킬 활용**을 통해 작업 모듈화를 할 수도 있음
    - 서브에이전트(혹은 skills) : 작업을 전문 영역별로 분할하여 해당 영역을 위해 전문화된 에이전트에게 전담하는 것. 정확도가 높아짐
    - ex) 데이터 모델 섹션만 알고 있는 데이터베이스 디자이너 서브에이전트와, API 엔드포인트 스펙만 아는 API 코더 서브에이전트를 둘 수 있음. 메인 에이전트(또는 오케스트레이터)는 작업을 적절한 서브에이전트로 자동으로 라우팅
    - Claude Code는 각 서브에이전트에 자체 시스템 프롬프트와 도구를 부여하는 방식으로 이를 지원
- 처리량 및 속도를 위해서 **병렬 에이전트**를 고려할 수 있음
    - 하나의 에이전트가 작업을 끝낼 때까지 기다리는 대신, 겹치지 않는 작업을 병렬 에이전트로 진행하는 것
    - 에이전트들이 서로 작업을 침범하지 않도록 범위를 잘 나누고, 스펙에 의존성을 분명히 명시해야 함
    ex) 에이전트 1은 기능 구현, 에이전트 2는 테스트 작성, 에이전트 3은 다른 컴포넌트 구축
    - 일반적인 패턴은 한 에이전트가 코드를 작성, 다른 에이전트가 병렬로 리뷰 수행 or 서로 다른 컴포넌트를 만든 뒤 나중에 통합
    - 여러 에이전트를 동시에 운영하는 것은 효과적이지만 정신적으로 매우 피곤하며, 관리 가능한 수준을 유지하려면 2~3개 정도로 시작하는 것이 좋음
    - 병렬 에이전트 설정을 위해 사용할 수 있는 툴들
        - 오케스트레이션 프레임워크 : LangGraph나 OpenAI Swarm 등. 에이전트 조율에 활용
        - 공유 메모리 : Chroma. 벡터 데이터베이스를 통한 공유 메모리를 제공하여 중복 프롬프트 없이 공통 컨텍스트에 접근할 수 있게 함
    - 단일 에이전트 vs 다중 에이전트
        
        
        | **항목** | **단일 에이전트** | **병렬 / 다중 에이전트** |
        | --- | --- | --- |
        | **강점** | 설정이 단순함, 오버헤드가 적음, 디버깅과 추적이 쉬움 | 처리량이 높음, 복잡한 상호 의존성 처리 가능, 도메인별 전문가 활용 |
        | **과제** | 대형 프로젝트에서 컨텍스트 과부하, 반복 속도가 느림, 단일 실패 지점 | 조정 오버헤드, 충돌 가능성, 공유 메모리 필요(예: 벡터 DB) |
        | **적합한 경우** | 독립적인 모듈, 소~중규모 프로젝트, 초기 프로토타이핑 | 대규모 코드베이스, 한 명은 코딩/테스트/리뷰, 독립 기능 |
        | **팁** | 스펙 요약 사용, 작업별 컨텍스트 갱신, 새 세션을 자주 시작 | 처음에는 2~3개 에이전트로 제한, MCP로 도구 공유, 명확한 경계 정의 |

## 4. 자체 점검, 제약, 사람의 전문성을 스펙에 반영하기

- 좋은 스펙은 AI가 실수할 수 있는 지점을 예측하고, 이를 막기 위한 **가드레일**을 설정하는 역할을 함
- 도메인 지식과 명확한 제약 조건을 스펙에 녹여 넣어 AI가 견고한 결과물을 만들도록 코치하기
- **3단계 경계(boundary) 시스템** 활용하기
    
    <img width="2784" height="1536" alt="image" src="https://github.com/user-attachments/assets/7160784b-b036-4d1e-9e0e-b0e560e8dcb6" />

    
    - [GitHub에서 2,500개 이상의 에이전트 파일을 분석](https://github.blog/ai-and-ml/github-copilot/how-to-write-a-great-agents-md-lessons-from-over-2500-repositories/)한 결과, 가장 효과적인 스펙들은 단순한 금지 목록 대신 에이전트의 행동을 명확히 구분하여 안내하는 3단계 경계 시스템을 사용하고 있음
        - **✅ 항상 해야 할 것 (Always do):** 질문 없이 자신있게 수행해야 할 작업 (예: 커밋 전 항상 테스트 실행, 스타일 가이드의 명명 규칙 따르기)
        - **⚠️ 먼저 물어볼 것 (Ask first):** 사람의 승인을 받아야 하는 작업 (예: DB 스키마 수정, 새로운 의존성 추가, CI/CD 변경) ⇒ 영향범위가 큰 변경 사항을 사람이 한 번 더 확인하게 해줌
        - **🚫 절대 하지 말 것 (Never do):** 명확한 금지 사항 (예: 비밀 정보 커밋, node_modules/나 vendor/ 직접 수정, 실패하는 테스트 제거하기)
- **자체 검증 장려** : 에이전트가 자신의 작업을 스펙에 비추어 스스로 검증하도록 만들기
    - 코드 생성 후 유닛 테스트나 린트 같은 체크를 실행하도록 통합
    - 스펙이나 프롬프트 수준에서도 AI에게 재확인 지시 가능
    - ex) 구현이 끝난 뒤, 결과를 스펙과 비교하고 모든 요구사항이 충족되었는지 확인하세요. 충족되지 않은 스펙 항목이 있다면 나열하세요.
- **LLM-as-a-Judge :** 자동으로 테스트하기 어려운 기준들(코드 스타일, 가독성, 아키텍처 패턴 준수 여부 등)을 검사하기 위한 전략
    - 두 번째 에이전트(또는 별도의 프롬프트)를 사용해 첫 번째 에이전트의 결과물을 스펙의 품질 가이드라인에 따라 검토하게 하는 방식
    - ex) 이 코드를 스타일 가이드 준수 여부 기준으로 리뷰하고, 위반 사항을 표시해 주세요
    - 심사 역할의 에이전트는 피드백을 반환하고, 이는 반영되거나 수정 작업을 촉발
    - 엔트로픽을 비롯한 여러 곳에서 이 방식이 주관적 평가에 효과적이라는 점을 확인(의미적 평가 계층 추가)
- **적합성 테스트(Conformance Test)** : 구현 세부사항에 독립적인 테스트를 스펙에 포함하기
    - 적합성 테스트 : 언어에 독립적인 테스트로, 어떤 구현이든 반드시 통과해야 하는 계약과 같음. 종종 YAML 기반으로 작성
    - ex)
        
        ```yaml
        # conformance/api-tests.yaml
        
        - test_name: "날짜 추출 테스트"
          input: "다음 주 금요일에 회의 잡아줘."
          expected_output:
            action: "create_event"
            date: "2023-10-27"  # (가정: 오늘이 2023-10-20일 때)
        
        - test_name: "날씨 질문 테스트"
          input: "오늘 서울 날씨 어때?"
          expected_output:
            action: "get_weather"
            location: "Seoul"
        ```
        
    - 구현 세부사항과 독립적이기 때문에 실제 구현이 나오지 않은 상황에서 스펙에 포함시킬 수 있으며, AI의 구현 수정에도 깨지지 않는 품질 기준으로서 기능
    - 스펙의 성공 기준(Success) 섹션에 이러한 적합성 기준을 포함시키는 것을 권장
    (예: “conformance/api-tests.yaml에 정의된 모든 케이스를 통과해야 함”)
    - 굳이 YAML 파일 기반의 테스트 형태가 아니더라도, 의사 코드나 기대 결과를 스펙에 포함시키면 구현 방향이 크게 좋아짐
    - 전용 테스트 에이전트를 두어 코드 에이전트의 출력을 지속적으로 검증하게 할 수도 있음
- **도메인 지식 반영하기** : 숙련된 사람만이 알 수 있는 인사이트를 스펙에 반영하기
    - ex) 상품과 카테고리는 다대다 관계여야 한다, 라이브러리 X를 사용할 경우 Y 버전에서 메모리 누수 문제가 있으므로 Z 워크어라운드를 적용할 것, 리액트에서는 클래스 컴포넌트보다 함수형 컴포넌트를 사용할 것 등
    - AI가 이를 스스로 추론할 것이라고 기대하지 말기

## 5. 스펙을 테스트하고 반복 개선하며 진화시키기

- 스펙 작성과 에이전트 구축은 반복적인 루프이며, 에이전트의 작업을 스펙에 지속적으로 대조하고 필요할 때마다 스펙을 조정해야 함
- 스펙 자체를 반복 개선하기
    - 에이전트가 뭔가 오해하거나 요구사항을 빠뜨릴 경우 스펙 문서 자체를 수정하기
    - 수정을 마치면 에이전트에게 명시적으로 동기화
    (ex: 스펙을 다음과 같이 업데이트했습니다. 업데이트된 스펙을 기준으로 계획을 수정하거나 코드를 리팩터링하세요)
    ⇒ 스펙을 단일 진실의 원천으로 유지
- 버전 관리와 스펙 잠금 : 스펙 파일 자체를 저장소에 커밋해서 변경 이력을 유지하면 에이전트가 스펙의 변화를 추적할 수 있음
- 비용과 속도 고려 : 모델 선택과 배치 전략을 현명하게 가져가기
    - 대형 모델 : 최종 결과, 복잡한 추론, 계획 수립, 핵심 단계에서 사용
    - 소형 모델 : 반복 작업, 초기 초안, 단순 리팩터링, 확장 작업, 테스트 실행, 린트 시 사용

# 흔히 저지르는 실수 피하기

### 모호한 프롬프트

- “뭔가 멋진 걸 만들어줘”, “더 잘 작동하게 해 줘” 같은 모호한 요청은 에이전트가 붙잡을 기준이 없어 잘못된 결과를 낳음
- 입력, 출력, 제약 조건을 명확히 하기
- ex)

  “당신은 유용한 코딩 어시스턴트입니다” (X)

  “당신은 리액트 컴포넌트를 위한 테스트를 작성하며, 이 예시들을 따르고, 소스 코드는 절대 수정하지 않는 테스트 엔지니어입니다” (O)

### 요약 없는 과도한 컨텍스트

- 문서 50페이지를 던져주고 모델이 알아서 하길 기다리면 실패함
- 계층적 요약이나 RAG를 사용해 관련된 것만 제공하기

### 사람의 리뷰 생략

- 테스트를 통과했다고 해서 코드가 안전하거나 유지보수 가능한 것은 아님
- 핵심 로직은 반드시 직접 리뷰하기

### **바이브 코딩과 프로덕션 엔지니어링 혼동**

- AI로 빠르게 프로토타이핑하는 “바이브 코딩”은 탐색 단계에서는 훌륭하지만 엄격한 스펙, 테스트, 리뷰 없이 바로 프로덕션에 올리는 것은 위험함
- “AI 보조 엔지니어링”은 이 가이드에서 설명한 규율을 요구함

### **‘치명적인 삼위일체’ 무시**

- AI 에이전트를 위험하게 만드는 세 가지 : 속도(검토보다 빠름), 비결정성(같은 입력 다른 출력), 비용(검증을 건너뛰게 부추김)
- 스펙과 리뷰 프로세스는 세 가지를 모두 고려해야 함

### 여섯 가지 핵심 영역 누락

- 2번 섹션의 여섯 영역(명령어, 테스트, 프로젝트 구조, 코드 스타일, Git 워크플로우, 경계 규칙)을 체크리스트로 활용하여 스펙에 모두 포함되어 있는지 점검하기

# 출처

https://ykss.netlify.app/translation/2026/how-to-write-a-good-spec-for-ai-agents/

https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with-a-new-open-source-toolkit/

https://10xdevelopers.dev/structured/claude-code-with-subagents/#subagents
